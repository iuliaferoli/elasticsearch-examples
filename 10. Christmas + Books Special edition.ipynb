{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See blog here: https://discuss.elastic.co/t/dec-18th-2023-en-the-most-magical-time-of-the-year-using-semantic-search-to-find-the-most-festive-harry-potter-moments/347615 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'instance-0000000000', 'cluster_name': 'fdcc4e10e5a34385884a3eda9350099a', 'cluster_uuid': '1v8os-EZTPmrZoF6uXeWKA', 'version': {'number': '8.9.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '8aa461beb06aa0417a231c345a1b8c38fb498a0d', 'build_date': '2023-07-19T14:43:58.555259655Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eland as ed\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import configparser\n",
    "import re\n",
    "import pandas as pd \n",
    "from json import loads\n",
    "\n",
    "from getpass import getpass  # For securely getting user input\n",
    "\n",
    "# Prompt the user to enter their Elastic Cloud ID and API Key securely\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "client = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY # API keys can be generated under management / security\n",
    ")\n",
    "\n",
    "\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the books as text file and processing them into the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_books = pd.read_csv(\"data/Harry_Potter_all_books_preprocessed.txt\", sep=\".\", header=None)\n",
    "hp_books = hp_books.T\n",
    "\n",
    "hp_books.rename(columns = {0:'text_field'}, inplace = True)\n",
    "\n",
    "docs = hp_books.to_json(orient = \"records\")\n",
    "hp_books = loads(docs)\n",
    "\n",
    "hp_books[0:5]\n",
    "\n",
    "index = \"hp_books\"\n",
    "settings = {}\n",
    "mappings = {\n",
    "    \"_meta\" : {\n",
    "        \"created_by\" : \"Iulia Feroli\"\n",
    "    },\n",
    "    \"properties\" : {\n",
    "        \"text_field\" : {\n",
    "            \"type\" : \"text\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "client.indices.create(index=index, settings=settings, mappings=mappings)\n",
    "response = bulk(client = client, index = index, actions = iter(hp_books), stats_only = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 203 results, here are the top ones:\n",
      "meeting before Christmas \n",
      "Merry Christmas said George \n",
      "See you at Christmas \n",
      "Come on Hermione its Christmas \n",
      "So Ive come for Christmas \n",
      "A Very Merry Christmas to you \n",
      "Christmas is a time for family \n",
      "Flaming Christmas puddings followed the turkey \n",
      "Christmas morning dawned cold and white \n",
      "Merry Christmas !See ?said Ron quietly \n"
     ]
    }
   ],
   "source": [
    "#test search\n",
    "index = \"hp_books\"\n",
    "response = client.search(index = index, query={\n",
    "    \"match\" : {\n",
    "        \"text_field\" : \"Christmas\"\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\"We get back {total} results, here are the top ones:\".format(total=response[\"hits\"]['total']['value']))\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit['_source']['text_field'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Elastic and creating a new enriched data index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".elser_model_1\n",
      "distilbert-base-uncased-finetuned-sst-2-english\n",
      "lang_ident_model_1\n",
      "sentence-transformers__msmarco-minilm-l-12-v3\n"
     ]
    }
   ],
   "source": [
    "#making sure the models are here - we will use the trxt classifier and elser at the same time\n",
    "from elasticsearch.client import MlClient\n",
    "models = MlClient.get_trained_models(client)\n",
    "for model in models[\"trained_model_configs\"]:\n",
    "    print(model[\"model_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'hp_books_enriched'})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "  index=\"hp_books_enriched\",\n",
    "  mappings={\n",
    "    \"properties\": {\n",
    "      \"text_field\": {\n",
    "        \"type\": \"text\"\n",
    "       },\n",
    "      \"sentiment\": {\n",
    "          \"properties\": {\n",
    "            \"model_id\": {\n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"keyword\": {\n",
    "                  \"type\": \"keyword\",\n",
    "                  \"ignore_above\": 256\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"predicted_value\": {\n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"keyword\": {\n",
    "                  \"type\": \"keyword\",\n",
    "                  \"ignore_above\": 256\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"prediction_probability\": {\n",
    "              \"type\": \"float\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "      \"ml.tokens\": { \n",
    "        \"type\": \"rank_features\" \n",
    "      }\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run both models in a single pipeline this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/sm4kh0y91fs5_fft4375wwh00000gn/T/ipykernel_3070/2458190572.py:30: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  client.reindex(body={\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'task': 'JqYuDbWsRueybLrxY3c9Cg:76870757'})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a pipeline\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"sentiment_and_elser\", \n",
    "    processors=[\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        \"target_field\" : \"sentiment\",\n",
    "        \"field_map\": {\n",
    "          \"Sentence\": \"text_field\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \".elser_model_1\",\n",
    "        \"target_field\": \"ml\",\n",
    "        \"field_map\": {\n",
    "          \"Sentence\": \"text_field\"\n",
    "        },\n",
    "        \"inference_config\": {\n",
    "          \"text_expansion\": {\n",
    "            \"results_field\": \"tokens\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "client.reindex(body={\n",
    "      \"source\": {\n",
    "          \"index\": \"hp_books\"},\n",
    "      \"dest\": {\"index\": \"hp_books_enriched\", \"pipeline\" : \"sentiment_and_elser\"}\n",
    "    }, wait_for_completion=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesing our new fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most unfortunate that it should happen on Christmas Day \n",
      "Christmas morning dawned cold and white \n",
      "What a jolly holiday its going to be \n",
      "Td invite you for Christmas but \n",
      "We can do all our Christmas shopping there !said Hermione \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/sm4kh0y91fs5_fft4375wwh00000gn/T/ipykernel_3070/2834304873.py:1: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  result = client.search(\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\n",
    "    index='hp_books_enriched', \n",
    "    size=5,\n",
    "    query={\n",
    "        \"text_expansion\": {\n",
    "            \"ml.tokens\": {\n",
    "                \"model_id\":\".elser_model_1\",\n",
    "                \"model_text\":\"christmas\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    request_timeout=30\n",
    ")\n",
    "\n",
    "for element in result[\"hits\"][\"hits\"]:\n",
    "        print(\"{}\".format(element[\"_source\"][\"text_field\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most unfortunate that it should happen on Christmas Day \n",
      "I have a lot to do before the holidays \n",
      "I wouldnt fancy having to go and tell the Irish theyve got to stop celebrating \n",
      "Christmas morning dawned cold and white \n",
      "Surely you want to go home for the holidays ?No said Riddle at once \n"
     ]
    }
   ],
   "source": [
    "result = client.search(\n",
    "    index='hp_books_enriched', \n",
    "    size=5,\n",
    "    query={\n",
    "        \"bool\": {\n",
    "            \"should\": [{\n",
    "                \"text_expansion\": {\n",
    "                    \"ml.tokens\": {\n",
    "                        \"model_id\":\".elser_model_1\",\n",
    "                        \"model_text\":\"celebrating the christmas holidays\"\n",
    "                    }\n",
    "                },\n",
    "            }],\n",
    "            \"must\":[\n",
    "            {\n",
    "                \"match\" : {\n",
    "                    \"sentiment.predicted_value\": \"NEGATIVE\"\n",
    "                }\n",
    "            }]}})\n",
    "    \n",
    "\n",
    "for element in result[\"hits\"][\"hits\"]:\n",
    "        print(element[\"_source\"][\"text_field\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most positive sentences in the series:\n",
      "Merry Christmas !he said happily raising his tankard \n",
      "A powerful and delicious smell of cooking pervaded the corridors and by Christmas Eve it had grown so strong that even Scabbers poked his nose out of the shelter of Rons pocket to sniff hopefully at the air \n",
      "Merry Christmas !See ?said Ron quietly \n",
      "Christmas spirit was definitely thin on the ground in the Gryffindor common room that morning \n",
      "Most unfortunate that it should happen on Christmas Day \n",
      "Merry Christmas !said Dumbledore as Harry Ron and Hermione approached the table \n",
      "What could possibly do that to a ghost ?people asked each other what terrible power could harm someone who was already dead ?There was almost a stampede to book seats on the Hogwarts Express so that students could go home for Christmas \n",
      "Thick streamers of holly and mistletoe were strung along the corridors mysterious lights shone from inside every suit of armor and the Great Hall was filled with its usual twelve Christmas trees glittering with golden stars \n",
      "The rest of Harrys Christmas presents were far more satisfactory \n",
      "He had already told them pompously that he was only staying over Christmas because it was his duty as a prefect to support the teachers during this troubled time \n"
     ]
    }
   ],
   "source": [
    "query={\n",
    "    \"match\" : {\n",
    "      \"sentiment.predicted_value\": \"POSITIVE\"\n",
    "    },\n",
    "    \"match\" : {\n",
    "        \"text_field\": \"Christmas\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "response = client.search(index = \"hp_books_enriched\",query=query, sort=\"sentiment.prediction_probability:desc\")\n",
    "\n",
    "print(\"The most positive sentences in the series:\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit['_source'][\"text_field\"] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
