{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ELSER\n",
    "\n",
    "Elastic also offers an out of the box semantic search model, optimized for context searches: Elastic Learned Sparse EncodeR, or ELSER.\n",
    "Let's try this one as well.\n",
    "\n",
    "See a full example of this here: https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/03-ELSER.ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'instance-0000000000', 'cluster_name': 'fdcc4e10e5a34385884a3eda9350099a', 'cluster_uuid': '1v8os-EZTPmrZoF6uXeWKA', 'version': {'number': '8.9.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '8aa461beb06aa0417a231c345a1b8c38fb498a0d', 'build_date': '2023-07-19T14:43:58.555259655Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eland as ed\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from getpass import getpass  # For securely getting user input\n",
    "\n",
    "# Prompt the user to enter their Elastic Cloud ID and API Key securely\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "es = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY # API keys can be generated under management / security\n",
    ")\n",
    "\n",
    "\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the ELSER model configuration. Automatically downloads the model if it doesn't exist.\n",
    "client.ml.put_trained_model(\n",
    "  model_id=\".elser_model_1\",\n",
    "  input={\n",
    "    \"field_names\": [\"text_field\"]\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ml.start_trained_model_deployment(\n",
    "  model_id=\".elser_model_1\",\n",
    "  number_of_allocations=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"elser-ingest-pipeline\", \n",
    "    description=\"Ingest pipeline for ELSER\",\n",
    "    processors=[\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \".elser_model_1\",\n",
    "        \"target_field\": \"ml\",\n",
    "        \"field_map\": {\n",
    "          \"Sentence\": \"text_field\"\n",
    "        },\n",
    "        \"inference_config\": {\n",
    "          \"text_expansion\": {\n",
    "            \"results_field\": \"tokens\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we are building a new index with the additional ml field that will receive the ELSER generated tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(\n",
    "  index=\"hp_elser\",\n",
    "  mappings={\n",
    "    \"properties\": {\n",
    "      \"text_embedding.predicted_value\": {\n",
    "        \"type\": \"dense_vector\",\n",
    "        \"dims\": 384,\n",
    "        \"index\": True,\n",
    "        \"similarity\": \"cosine\"\n",
    "      },\n",
    "      \"Character\": {\n",
    "          \"type\": \"text\"\n",
    "      },\n",
    "      \"Line_number\": {\n",
    "        \"type\": \"long\"\n",
    "      },\n",
    "      \"Sentence\": {\n",
    "        \"type\": \"text\"\n",
    "       },\n",
    "      \"sentiment\": {\n",
    "          \"properties\": {\n",
    "            \"model_id\": {\n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"keyword\": {\n",
    "                  \"type\": \"keyword\",\n",
    "                  \"ignore_above\": 256\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"predicted_value\": {\n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"keyword\": {\n",
    "                  \"type\": \"keyword\",\n",
    "                  \"ignore_above\": 256\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"prediction_probability\": {\n",
    "              \"type\": \"float\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "      \"ml.tokens\": { \n",
    "        \"type\": \"rank_features\" \n",
    "      }\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reindex(body={\n",
    "      \"source\": {\n",
    "          \"index\": \"hp_scripts_final\"},\n",
    "      \"dest\": {\n",
    "    \"index\": \"hp_elser\",\n",
    "    \"pipeline\": \"elser-ingest-pipeline\"\n",
    "    }}, wait_for_completion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.search(\n",
    "    index='hp_elser', \n",
    "    size=5,\n",
    "    query={\n",
    "        \"text_expansion\": {\n",
    "            \"ml.tokens\": {\n",
    "                \"model_id\":\".elser_model_1\",\n",
    "                \"model_text\":\"brave\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUPIN: Be brave, score 12.215565\n",
      "LUCIUS MALFOY: You must be very brave to mention his name, score 7.7868624\n",
      "Sorting Hat: Plenty of courage I see, score 7.384922\n",
      "Dumbledore: And finally it takes a great deal of bravery to stand up to your enemies but a great deal more to stand up to your friends, score 6.109682\n",
      "Voldemort: Haha Bravery Your parents had it too, score 5.6515555\n"
     ]
    }
   ],
   "source": [
    "for element in result[\"hits\"][\"hits\"]:\n",
    "        print(\"{}: {}, score {}\".format(element[\"_source\"][\"Character\"], element[\"_source\"][\"Sentence\"], element[\"_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the sentiment to the semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUPIN: Dumbledore has already risked enough on my behalf\n",
      "LUPIN: That suggests what you fear the most is fear itself\n",
      "Hagrid: Fine Just so you know hes a bloody coward \n",
      "SNAPE: Do I detect a flicker of fear\n",
      "MCGONAGALL: Our worst fear has been realized\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\n",
    "    index='hp_elser', \n",
    "    size=5,\n",
    "    query={\n",
    "        \"bool\": {\n",
    "            \"should\": [{\n",
    "                \"text_expansion\": {\n",
    "                    \"ml.tokens\": {\n",
    "                        \"model_id\":\".elser_model_1\",\n",
    "                        \"model_text\":\"brave\"\n",
    "                    }\n",
    "                },\n",
    "            }],\n",
    "            \"must\":[\n",
    "            {\n",
    "                \"match\" : {\n",
    "                    \"sentiment.predicted_value\": \"NEGATIVE\"\n",
    "                }\n",
    "            }]}})\n",
    "for element in result[\"hits\"][\"hits\"]:\n",
    "        print(\"{}: {}\".format(element[\"_source\"][\"Character\"], element[\"_source\"][\"Sentence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUPIN: Dumbledore has already risked enough on my behalf\n",
      "Hagrid: Fine Just so you know hes a bloody coward \n",
      "GILDEROY LOCKHART: You may find yourselves facing your worst fears in this room\n",
      "Hagrid: What if the other dragons are mean to him\n",
      "TOM RIDDLE: Im afraid I cant do that\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\n",
    "    index='hp_elser', \n",
    "    size=5,\n",
    "    query={\n",
    "        \"bool\": {\n",
    "            \"should\": [{\n",
    "                \"text_expansion\": {\n",
    "                    \"ml.tokens\": {\n",
    "                        \"model_id\":\".elser_model_1\",\n",
    "                        \"model_text\":\"brave\"\n",
    "                    }\n",
    "                },\n",
    "            }],\n",
    "            \"must\":[\n",
    "            {\n",
    "                \"match\" : {\n",
    "                    \"sentiment.predicted_value\": \"NEGATIVE\"\n",
    "                }\n",
    "            }],\n",
    "            \"must_not\":[\n",
    "                    {\"term\":{\n",
    "                        \"Sentence\":\"fear\"\n",
    "                 }}]\n",
    "        }\n",
    "    })\n",
    "\n",
    "for element in result[\"hits\"][\"hits\"]:\n",
    "        print(\"{}: {}\".format(element[\"_source\"][\"Character\"], element[\"_source\"][\"Sentence\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
